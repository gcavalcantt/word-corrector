{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DVbBn4j1droc",
        "gAcBILtVkeA9",
        "OKv2nKShnVWA",
        "jgvECJci7t7r",
        "E1vZ0DhaxPNt",
        "r3TShMx5D74A"
      ],
      "authorship_tag": "ABX9TyNrvu0OfSALbqienrjzeEB0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word Corrector Project with Natural Language Processing (NLP)\n",
        "\n",
        "The aim of this project is to develop a word corrector using Natural Language Processing (NLP) according to the grammar of the Portuguese language (PT-BR)."
      ],
      "metadata": {
        "id": "Lz_hogyymAys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "DVbBn4j1droc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tr-ZODRaAZU",
        "outputId": "d8a62d38-9b12-412b-8fee-3f4d40123d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Área de Estudos/Alura/Formações/Python para Data Science/Versao_1/python_database/curso7-corretor-nlp/artigos.txt\", \"r\") as f:\n",
        "    articles = f.read()\n",
        "\n",
        "print(articles[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uveu-lMFb2LR",
        "outputId": "18d2bda3-943c-45ec-86cd-214b78bb25fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "imagem \n",
            "\n",
            "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
            "\n",
            "java\n",
            "\n",
            "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
            "\n",
            "java \n",
            "\n",
            "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "gAcBILtVkeA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(articles)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JioiqZ7cSzo",
        "outputId": "6b1ab50f-b922-48ac-b2f1-6528b719f76f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2605046"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(\"Olá\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tyv6OnwVcceg",
        "outputId": "bd3e81b7-7281-42ab-fa67-e829a51c712b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"Hello! How is it going?\"\n",
        "tokens = example_text.split()"
      ],
      "metadata": {
        "id": "pWN_iFWqcic3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTYfCwmfd94h",
        "outputId": "212d43d8-7454-4190-a5b6-8af955442df6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bzn23Pe8eXUU",
        "outputId": "6553b6ee-508e-4035-823e-153be9ed8cbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello!', 'How', 'is', 'it', 'going?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "separated_words = nltk.tokenize.word_tokenize(example_text)                     # Separating my tokens to remove special characters and other unnecessary records\n",
        "\n",
        "print(separated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmXgeK1uea0z",
        "outputId": "5d67ec76-281b-4384-ba6e-479722d34c62"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', '!', 'How', 'is', 'it', 'going', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(separated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GcJU1PkiItq",
        "outputId": "90bea081-68b1-4c05-e228-78755f8fa638"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', '!', 'How', 'is', 'it', 'going', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(separated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAxuRdEMiTFQ",
        "outputId": "41291504-0594-4b1e-bde7-f52586d88f33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'./'.isalpha()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwCY-6EpiYw_",
        "outputId": "81fe89d0-190a-441c-d77a-e9627581b8e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_words(token_list):                                                 # Function that returns only the words without special characters\n",
        "    word_list = []\n",
        "    for token in token_list:\n",
        "        if token.isalpha():                                                     # isalpha(): checks if all characters in the token are alphabetic, if true, it's stored in the variable\n",
        "            word_list.append(token)\n",
        "    return word_list\n",
        "\n",
        "separate_words(separated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fcNlMQuibRd",
        "outputId": "1fc16bd5-32c3-48ee-a33d-18b174bb2a68"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello', 'How', 'is', 'it', 'going']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_list = nltk.tokenize.word_tokenize(articles)\n",
        "word_list = separate_words(token_list)\n",
        "\n",
        "print(f\"The number of words is {len(word_list)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRUV5Wnii4Y-",
        "outputId": "64f0c472-43ae-4f36-bb26-16017fcf93e0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of words is 403104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsVASDWMj6St",
        "outputId": "c72895e6-e819-48c1-db83-f279444fce45"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imagem', 'Temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalization(word_list):\n",
        "    normalized_list = []\n",
        "    for word in word_list:\n",
        "        normalized_list.append(word.lower())                                    # Standardizing words to all be lowercase\n",
        "    return normalized_list\n",
        "\n",
        "normalized_list = normalization(word_list)\n",
        "print(normalized_list[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd2NdqqNkGzB",
        "outputId": "ca427be8-a8c6-423f-910c-92fe56ac197f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(normalized_list))                                                       # Removing duplicate words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phI7rowJkjhQ",
        "outputId": "73c6daa5-156f-4b2e-b980-bda254f35218"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18465"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Corrector"
      ],
      "metadata": {
        "id": "OKv2nKShnVWA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the Corrector"
      ],
      "metadata": {
        "id": "jgvECJci7t7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list = \"lgica\"\n",
        "(list[:1],list[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNYhyN1OlySy",
        "outputId": "aeca6262-0e87-4eda-814b-388c5ff97a57"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('l', 'gica')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_word = \"lgica\"\n",
        "\n",
        "# Inserting letters into our example word\n",
        "def insert_letters(slices):\n",
        "    new_words = []\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
        "    for left, right in slices:                                                  # Left == left // Right == right\n",
        "        for letter in letters:                                                  # List of words with all possible letters\n",
        "            new_words.append(left + letter + right)                             # (L + [letter] + gica)\n",
        "    return new_words\n",
        "\n",
        "# Generating different word possibilities\n",
        "def word_generator(word):\n",
        "    slices = []\n",
        "    for i in range(len(word)+1):\n",
        "        slices.append((word[:i], word[i:]))                                     # Inserting slices into the word generator\n",
        "    generated_words = insert_letters(slices)                                    # Inserting letters into the word generator\n",
        "    return generated_words\n",
        "\n",
        "generated_words = word_generator(example_word)\n",
        "print(generated_words)\n",
        "print(example_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2aesNBXmB7_",
        "outputId": "8263ad3d-b072-4961-e0e1-2f88427dbadc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'álgica', 'âlgica', 'àlgica', 'ãlgica', 'élgica', 'êlgica', 'èlgica', 'ẽlgica', 'ílgica', 'îlgica', 'ìlgica', 'ĩlgica', 'ólgica', 'ôlgica', 'õlgica', 'òlgica', 'úlgica', 'ûlgica', 'ùlgica', 'ũlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'lágica', 'lâgica', 'làgica', 'lãgica', 'légica', 'lêgica', 'lègica', 'lẽgica', 'lígica', 'lîgica', 'lìgica', 'lĩgica', 'lógica', 'lôgica', 'lõgica', 'lògica', 'lúgica', 'lûgica', 'lùgica', 'lũgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgáica', 'lgâica', 'lgàica', 'lgãica', 'lgéica', 'lgêica', 'lgèica', 'lgẽica', 'lgíica', 'lgîica', 'lgìica', 'lgĩica', 'lgóica', 'lgôica', 'lgõica', 'lgòica', 'lgúica', 'lgûica', 'lgùica', 'lgũica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiáca', 'lgiâca', 'lgiàca', 'lgiãca', 'lgiéca', 'lgiêca', 'lgièca', 'lgiẽca', 'lgiíca', 'lgiîca', 'lgiìca', 'lgiĩca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiòca', 'lgiúca', 'lgiûca', 'lgiùca', 'lgiũca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicáa', 'lgicâa', 'lgicàa', 'lgicãa', 'lgicéa', 'lgicêa', 'lgicèa', 'lgicẽa', 'lgicía', 'lgicîa', 'lgicìa', 'lgicĩa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicòa', 'lgicúa', 'lgicûa', 'lgicùa', 'lgicũa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaá', 'lgicaâ', 'lgicaà', 'lgicaã', 'lgicaé', 'lgicaê', 'lgicaè', 'lgicaẽ', 'lgicaí', 'lgicaî', 'lgicaì', 'lgicaĩ', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaò', 'lgicaú', 'lgicaû', 'lgicaù', 'lgicaũ', 'lgicaç']\n",
            "lgica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def corrector(word):                                                            # Function that generates the word corrector\n",
        "    generated_words = word_generator(word)\n",
        "    correct_word = max(generated_words, key=probability)                        # The correct word is defined by the word with the highest probability among the generated words\n",
        "    return correct_word"
      ],
      "metadata": {
        "id": "5F3as804pZOl"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequency = nltk.FreqDist(normalized_list)                                      # Calculating the frequency of each word\n",
        "total_words = len(normalized_list)\n",
        "frequency.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0oj0FYAxGem",
        "outputId": "9a946593-81c7-4330-a05a-95708fe69d73"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 15502),\n",
              " ('o', 14056),\n",
              " ('que', 12230),\n",
              " ('a', 11099),\n",
              " ('e', 10501),\n",
              " ('para', 7710),\n",
              " ('um', 6368),\n",
              " ('é', 5899),\n",
              " ('uma', 5220),\n",
              " ('do', 5124)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def probability(generated_word):                                                # Function for word probability to analyze their frequency whenever needed\n",
        "    return frequency[generated_word] / total_words\n",
        "\n",
        "probability(\"logic\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mojIkXTz34hB",
        "outputId": "d03261b2-c457-43bd-89d9-20c6d8872f66"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probability(\"lógica\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJjPTYmL54gJ",
        "outputId": "48c4451f-084d-4597-fc42-d48f1a49bbe1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.00023815194093831864"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corrector(example_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mxTpbpL66Beh",
        "outputId": "1f95cfaf-3b2b-40cd-f59c-65f6febf72e5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lógica'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing a new file to perform a word correction test\n",
        "def create_test_data(file_name):\n",
        "    test_word_list = []\n",
        "    f = open(file_name, \"r\")\n",
        "    for line in f:                                                              # Creates a list which separates the lines from my database into two fields, one with correctly spelled words and the other not\n",
        "        correct, wrong = line.split()\n",
        "        test_word_list.append((correct, wrong))\n",
        "    f.close()\n",
        "    return test_word_list\n",
        "\n",
        "test_list = create_test_data(\"/content/drive/MyDrive/Área de Estudos/Alura/Formações/Python para Data Science/Versao_1/python_database/curso7-corretor-nlp/palavras.txt\")\n",
        "test_list"
      ],
      "metadata": {
        "id": "1i20B5X06Kvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4704c65d-7ad8-4cc3-e9df-17426e1f0a35"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('podemos', 'pyodemos'),\n",
              " ('esse', 'esje'),\n",
              " ('já', 'jrá'),\n",
              " ('nosso', 'nossov'),\n",
              " ('são', 'sãêo'),\n",
              " ('dos', 'dosa'),\n",
              " ('muito', 'muifo'),\n",
              " ('imagem', 'iômagem'),\n",
              " ('sua', 'ósua'),\n",
              " ('também', 'tambéùm'),\n",
              " ('ele', 'eme'),\n",
              " ('fazer', 'èazer'),\n",
              " ('temos', 'temfs'),\n",
              " ('essa', 'eàssa'),\n",
              " ('quando', 'quaôdo'),\n",
              " ('vamos', 'vamvos'),\n",
              " ('sobre', 'hsobre'),\n",
              " ('java', 'sjava'),\n",
              " ('das', 'daõs'),\n",
              " ('agora', 'agorah'),\n",
              " ('está', 'eòtá'),\n",
              " ('cada', 'céda'),\n",
              " ('mesmo', 'zmesmo'),\n",
              " ('nos', 'noâ'),\n",
              " ('forma', 'fobma'),\n",
              " ('seja', 'sejéa'),\n",
              " ('então', 'enêão'),\n",
              " ('criar', 'èriar'),\n",
              " ('código', 'cóeigo'),\n",
              " ('caso', 'casío'),\n",
              " ('exemplo', 'áexemplo'),\n",
              " ('tem', 'tĩem'),\n",
              " ('usuário', 'usuárôio'),\n",
              " ('dados', 'dfados'),\n",
              " ('python', 'pgthon'),\n",
              " ('nossa', 'nossah'),\n",
              " ('além', 'alémè'),\n",
              " ('assim', 'asõim'),\n",
              " ('ter', 'teb'),\n",
              " ('até', 'atĩ'),\n",
              " ('bem', 'âem'),\n",
              " ('design', 'desigen'),\n",
              " ('trabalho', 'trabalàho'),\n",
              " ('foi', 'foo'),\n",
              " ('apenas', 'apenaũ'),\n",
              " ('empresa', 'empresà'),\n",
              " ('valor', 'valíor'),\n",
              " ('será', 'serr'),\n",
              " ('entre', 'entke'),\n",
              " ('método', 'méqodo'),\n",
              " ('precisamos', 'precisamops'),\n",
              " ('ainda', 'ainàa'),\n",
              " ('vai', 'van'),\n",
              " ('conteúdo', 'ûconteúdo'),\n",
              " ('seus', 'çeus'),\n",
              " ('eu', 'eû'),\n",
              " ('todos', 'todtos'),\n",
              " ('tempo', 'temeo'),\n",
              " ('sempre', 'semre'),\n",
              " ('qual', 'quakl'),\n",
              " ('ela', 'elaá'),\n",
              " ('só', 'síó'),\n",
              " ('utilizar', 'utiqizar'),\n",
              " ('projeto', 'prhojeto'),\n",
              " ('site', 'siàe'),\n",
              " ('sem', 'seém'),\n",
              " ('pelo', 'peln'),\n",
              " ('alura', 'aléra'),\n",
              " ('dia', 'tdia'),\n",
              " ('tudo', 'tuúo'),\n",
              " ('podemos', 'kpodemos'),\n",
              " ('esse', 'eẽsse'),\n",
              " ('já', 'jé'),\n",
              " ('nosso', 'nçosso'),\n",
              " ('são', 'sãô'),\n",
              " ('dos', 'odos'),\n",
              " ('muito', 'tuito'),\n",
              " ('imagem', 'imõgem'),\n",
              " ('sua', 'siua'),\n",
              " ('também', 'tamvbém'),\n",
              " ('ele', 'elpe'),\n",
              " ('fazer', 'façzer'),\n",
              " ('temos', 'teos'),\n",
              " ('essa', 'eũsa'),\n",
              " ('quando', 'quaìdo'),\n",
              " ('vamos', 'vjmos'),\n",
              " ('sobre', 'sxobre'),\n",
              " ('java', 'jkva'),\n",
              " ('das', 'dms'),\n",
              " ('agora', 'agtora'),\n",
              " ('está', 'esútá'),\n",
              " ('cada', 'cava'),\n",
              " ('mesmo', 'medmo'),\n",
              " ('nos', 'ános'),\n",
              " ('forma', 'forûa'),\n",
              " ('seja', 'smeja'),\n",
              " ('então', 'enjtão'),\n",
              " ('criar', 'criôar'),\n",
              " ('código', 'cóàigo'),\n",
              " ('caso', 'èaso'),\n",
              " ('exemplo', 'exbemplo'),\n",
              " ('tem', 'túem'),\n",
              " ('usuário', 'usuárin'),\n",
              " ('dados', 'daáos'),\n",
              " ('python', 'pythoçn'),\n",
              " ('nossa', 'nossk'),\n",
              " ('além', 'âlém'),\n",
              " ('assim', 'aóssim'),\n",
              " ('ter', 'tãer'),\n",
              " ('até', 'vté'),\n",
              " ('bem', 'búm'),\n",
              " ('design', 'íesign'),\n",
              " ('trabalho', 'trabèalho'),\n",
              " ('foi', 'kfoi'),\n",
              " ('apenas', 'aapenas'),\n",
              " ('empresa', 'pmpresa'),\n",
              " ('valor', 'valoqr'),\n",
              " ('será', 'sçerá'),\n",
              " ('entre', 'entró'),\n",
              " ('método', 'nétodo'),\n",
              " ('precisamos', 'prefcisamos'),\n",
              " ('ainda', 'sainda'),\n",
              " ('vai', 'uai'),\n",
              " ('conteúdo', 'cĩonteúdo'),\n",
              " ('seus', 'sâus'),\n",
              " ('eu', 'ìeu'),\n",
              " ('todos', 'todás'),\n",
              " ('tempo', 'utempo'),\n",
              " ('sempre', 'sempce'),\n",
              " ('qual', 'fual'),\n",
              " ('ela', 'elal'),\n",
              " ('só', 'skó'),\n",
              " ('utilizar', 'utilĩzar'),\n",
              " ('projeto', 'proójeto'),\n",
              " ('site', 'isite'),\n",
              " ('sem', 'secm'),\n",
              " ('pelo', 'pẽlo'),\n",
              " ('alura', 'aluéa'),\n",
              " ('dia', 'dil'),\n",
              " ('tudo', 'tudy'),\n",
              " ('ela', 'qelay'),\n",
              " ('só', 'sód'),\n",
              " ('utilizar', 'dtilizacr'),\n",
              " ('projeto', 'bprojõto'),\n",
              " ('site', 'ysiteo'),\n",
              " ('sem', 'sõêm'),\n",
              " ('pelo', 'peàli'),\n",
              " ('alura', 'asuraó'),\n",
              " ('dia', 'deiìa'),\n",
              " ('tudo', 'tuĩdoì'),\n",
              " ('ela', 'eúaa'),\n",
              " ('só', 'ró'),\n",
              " ('utilizar', 'utilizẽaçr'),\n",
              " ('projeto', 'prêjetó'),\n",
              " ('site', 'sqiqte'),\n",
              " ('sem', 'sũexm'),\n",
              " ('pelo', 'pçlxo'),\n",
              " ('alura', 'uluraa'),\n",
              " ('dia', 'dĩaz'),\n",
              " ('tudo', 'kzudo'),\n",
              " ('corretor', 'correptor'),\n",
              " ('tática', 'trtica'),\n",
              " ('empoderamento', 'ewpoderamento'),\n",
              " ('linux', 'lifux'),\n",
              " ('cachorro', 'cachoçro'),\n",
              " ('gato', 'îgato'),\n",
              " ('cavalo', 'cakvalo'),\n",
              " ('relógio', 'relógiuo'),\n",
              " ('canela', 'canelac'),\n",
              " ('tênis', 'tênisy'),\n",
              " ('ansiosa', 'anciosa'),\n",
              " ('ansiosa', 'ancciosa'),\n",
              " ('ansiosa', 'ansioa'),\n",
              " ('empoderamento', 'empoderamento'),\n",
              " ('asterisco', 'asterístico'),\n",
              " ('gratuito', 'gratuíto'),\n",
              " ('entretido', 'entertido'),\n",
              " ('ritmo', 'ritimo'),\n",
              " ('idiota', 'indiota'),\n",
              " ('tomara', 'tomare'),\n",
              " ('seja', 'seje'),\n",
              " ('prevalecer', 'provalecer'),\n",
              " ('esteja', 'esteje'),\n",
              " ('mendigo', 'mindigo'),\n",
              " ('cérebro', 'célebro'),\n",
              " ('perturbar', 'pertubar')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluator(tests):\n",
        "    word_count = len(tests)\n",
        "    correct_count = 0\n",
        "    for correct, wrong in tests:                                                # Returns the count of correctly corrected words based on the correct word\n",
        "        corrected_word = corrector(wrong)\n",
        "        if corrected_word == correct:\n",
        "            correct_count += 1\n",
        "    accuracy_rate = round(correct_count * 100 / word_count, 2)                  # Rounds the evaluator's result to two decimal places\n",
        "    print(f\"{accuracy_rate}% of {word_count} words\")\n",
        "\n",
        "evaluator(test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tQabOmj93Fn",
        "outputId": "37bb8bb2-3c0d-4ac1-d6a2-ad57afd01d55"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.08% of 186 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def deleting_characters(slices):\n",
        "    new_words = []\n",
        "    for left, right in slices:\n",
        "        new_words.append(left + right[1:])\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "xkJ9Lhei_S2L"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_generator(word):\n",
        "    slices = []\n",
        "    for i in range(len(word)+1):\n",
        "        slices.append((word[:i], word[i:]))\n",
        "    generated_words = insert_letters(slices)                                    # Inserts possible letters to generate the corrected word\n",
        "    generated_words += deleting_characters(slices)                              # Returns the generated words with removed characters\n",
        "    return generated_words\n",
        "example_word = \"lóigica\"\n",
        "generated_words = word_generator(example_word)\n",
        "print(generated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqKCut7dtwFy",
        "outputId": "9f2f7e61-cc56-4a00-844c-2e01f8445311"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'álóigica', 'âlóigica', 'àlóigica', 'ãlóigica', 'élóigica', 'êlóigica', 'èlóigica', 'ẽlóigica', 'ílóigica', 'îlóigica', 'ìlóigica', 'ĩlóigica', 'ólóigica', 'ôlóigica', 'õlóigica', 'òlóigica', 'úlóigica', 'ûlóigica', 'ùlóigica', 'ũlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'láóigica', 'lâóigica', 'làóigica', 'lãóigica', 'léóigica', 'lêóigica', 'lèóigica', 'lẽóigica', 'líóigica', 'lîóigica', 'lìóigica', 'lĩóigica', 'lóóigica', 'lôóigica', 'lõóigica', 'lòóigica', 'lúóigica', 'lûóigica', 'lùóigica', 'lũóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóáigica', 'lóâigica', 'lóàigica', 'lóãigica', 'lóéigica', 'lóêigica', 'lóèigica', 'lóẽigica', 'lóíigica', 'lóîigica', 'lóìigica', 'lóĩigica', 'lóóigica', 'lóôigica', 'lóõigica', 'lóòigica', 'lóúigica', 'lóûigica', 'lóùigica', 'lóũigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiágica', 'lóiâgica', 'lóiàgica', 'lóiãgica', 'lóiégica', 'lóiêgica', 'lóiègica', 'lóiẽgica', 'lóiígica', 'lóiîgica', 'lóiìgica', 'lóiĩgica', 'lóiógica', 'lóiôgica', 'lóiõgica', 'lóiògica', 'lóiúgica', 'lóiûgica', 'lóiùgica', 'lóiũgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigáica', 'lóigâica', 'lóigàica', 'lóigãica', 'lóigéica', 'lóigêica', 'lóigèica', 'lóigẽica', 'lóigíica', 'lóigîica', 'lóigìica', 'lóigĩica', 'lóigóica', 'lóigôica', 'lóigõica', 'lóigòica', 'lóigúica', 'lóigûica', 'lóigùica', 'lóigũica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiáca', 'lóigiâca', 'lóigiàca', 'lóigiãca', 'lóigiéca', 'lóigiêca', 'lóigièca', 'lóigiẽca', 'lóigiíca', 'lóigiîca', 'lóigiìca', 'lóigiĩca', 'lóigióca', 'lóigiôca', 'lóigiõca', 'lóigiòca', 'lóigiúca', 'lóigiûca', 'lóigiùca', 'lóigiũca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicáa', 'lóigicâa', 'lóigicàa', 'lóigicãa', 'lóigicéa', 'lóigicêa', 'lóigicèa', 'lóigicẽa', 'lóigicía', 'lóigicîa', 'lóigicìa', 'lóigicĩa', 'lóigicóa', 'lóigicôa', 'lóigicõa', 'lóigicòa', 'lóigicúa', 'lóigicûa', 'lóigicùa', 'lóigicũa', 'lóigicça', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaá', 'lóigicaâ', 'lóigicaà', 'lóigicaã', 'lóigicaé', 'lóigicaê', 'lóigicaè', 'lóigicaẽ', 'lóigicaí', 'lóigicaî', 'lóigicaì', 'lóigicaĩ', 'lóigicaó', 'lóigicaô', 'lóigicaõ', 'lóigicaò', 'lóigicaú', 'lóigicaû', 'lóigicaù', 'lóigicaũ', 'lóigicaç', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic', 'lóigica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator(test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5lj-riIvUJC",
        "outputId": "74755f7d-e76b-4b98-c44f-070aa9a75106"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41.4% of 186 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There was a clear improvement in the percentage of evaluated words."
      ],
      "metadata": {
        "id": "lTef3RcuwaVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correcting Typing Errors"
      ],
      "metadata": {
        "id": "E1vZ0DhaxPNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_letters(slices):\n",
        "    new_words = []\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
        "    for left, right in slices:\n",
        "        for letter in letters:\n",
        "            new_words.append(left + letter + right)                             # Inserts the letter between the word\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "7tZdXuSQwV5q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deleting_characters(slices):\n",
        "    new_words = []\n",
        "    for left, right in slices:\n",
        "        new_words.append(left + right[1:])                                      # On the right side, deletes the second character of the word and returns the second letter onwards\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "-3h7hg3uxBSp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_letter(slices):\n",
        "    new_words = []\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyzáâàãéêèẽíîìĩóôõòúûùũç'\n",
        "    for left, right in slices:\n",
        "        for letter in letters:\n",
        "            new_words.append(left + letter + right[1:])                         # On the right side, replaces the second letter of the word and returns the second letter onwards\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "a-yJlA90xDKC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_letter(slices):\n",
        "    new_words = []\n",
        "    for left, right in slices:\n",
        "        if len(right) > 1:\n",
        "            new_words.append(left + right[1] + right[0] + right[2:])            # On the right side, inverts the second letter with the first letter and returns the third letter onwards\n",
        "    return new_words"
      ],
      "metadata": {
        "id": "0G3X2wPyxE8Y"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing corrections in the word generator\n",
        "def word_generator(word):\n",
        "    slices = []\n",
        "    for i in range(len(word)+1):\n",
        "        slices.append((word[:i], word[i:]))\n",
        "    generated_words = insert_letters(slices)\n",
        "    generated_words += deleting_characters(slices)\n",
        "    generated_words += replace_letter(slices)\n",
        "    generated_words += invert_letter(slices)\n",
        "    return generated_words"
      ],
      "metadata": {
        "id": "SxQK5sxlxGnk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator(test_list)\n",
        "example_word = \"lógiac\"\n",
        "generated_words = word_generator(example_word)\n",
        "print(generated_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCtxLQxcxI3W",
        "outputId": "7f5ef1d6-ccea-4119-cb54-b77dbd25bf7b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.34% of 186 words\n",
            "['alógiac', 'blógiac', 'clógiac', 'dlógiac', 'elógiac', 'flógiac', 'glógiac', 'hlógiac', 'ilógiac', 'jlógiac', 'klógiac', 'llógiac', 'mlógiac', 'nlógiac', 'ológiac', 'plógiac', 'qlógiac', 'rlógiac', 'slógiac', 'tlógiac', 'ulógiac', 'vlógiac', 'wlógiac', 'xlógiac', 'ylógiac', 'zlógiac', 'álógiac', 'âlógiac', 'àlógiac', 'ãlógiac', 'élógiac', 'êlógiac', 'èlógiac', 'ẽlógiac', 'ílógiac', 'îlógiac', 'ìlógiac', 'ĩlógiac', 'ólógiac', 'ôlógiac', 'õlógiac', 'òlógiac', 'úlógiac', 'ûlógiac', 'ùlógiac', 'ũlógiac', 'çlógiac', 'laógiac', 'lbógiac', 'lcógiac', 'ldógiac', 'leógiac', 'lfógiac', 'lgógiac', 'lhógiac', 'liógiac', 'ljógiac', 'lkógiac', 'llógiac', 'lmógiac', 'lnógiac', 'loógiac', 'lpógiac', 'lqógiac', 'lrógiac', 'lsógiac', 'ltógiac', 'luógiac', 'lvógiac', 'lwógiac', 'lxógiac', 'lyógiac', 'lzógiac', 'láógiac', 'lâógiac', 'làógiac', 'lãógiac', 'léógiac', 'lêógiac', 'lèógiac', 'lẽógiac', 'líógiac', 'lîógiac', 'lìógiac', 'lĩógiac', 'lóógiac', 'lôógiac', 'lõógiac', 'lòógiac', 'lúógiac', 'lûógiac', 'lùógiac', 'lũógiac', 'lçógiac', 'lóagiac', 'lóbgiac', 'lócgiac', 'lódgiac', 'lóegiac', 'lófgiac', 'lóggiac', 'lóhgiac', 'lóigiac', 'lójgiac', 'lókgiac', 'lólgiac', 'lómgiac', 'lóngiac', 'lóogiac', 'lópgiac', 'lóqgiac', 'lórgiac', 'lósgiac', 'lótgiac', 'lóugiac', 'lóvgiac', 'lówgiac', 'lóxgiac', 'lóygiac', 'lózgiac', 'lóágiac', 'lóâgiac', 'lóàgiac', 'lóãgiac', 'lóégiac', 'lóêgiac', 'lóègiac', 'lóẽgiac', 'lóígiac', 'lóîgiac', 'lóìgiac', 'lóĩgiac', 'lóógiac', 'lóôgiac', 'lóõgiac', 'lóògiac', 'lóúgiac', 'lóûgiac', 'lóùgiac', 'lóũgiac', 'lóçgiac', 'lógaiac', 'lógbiac', 'lógciac', 'lógdiac', 'lógeiac', 'lógfiac', 'lóggiac', 'lóghiac', 'lógiiac', 'lógjiac', 'lógkiac', 'lógliac', 'lógmiac', 'lógniac', 'lógoiac', 'lógpiac', 'lógqiac', 'lógriac', 'lógsiac', 'lógtiac', 'lóguiac', 'lógviac', 'lógwiac', 'lógxiac', 'lógyiac', 'lógziac', 'lógáiac', 'lógâiac', 'lógàiac', 'lógãiac', 'lógéiac', 'lógêiac', 'lógèiac', 'lógẽiac', 'lógíiac', 'lógîiac', 'lógìiac', 'lógĩiac', 'lógóiac', 'lógôiac', 'lógõiac', 'lógòiac', 'lógúiac', 'lógûiac', 'lógùiac', 'lógũiac', 'lógçiac', 'lógiaac', 'lógibac', 'lógicac', 'lógidac', 'lógieac', 'lógifac', 'lógigac', 'lógihac', 'lógiiac', 'lógijac', 'lógikac', 'lógilac', 'lógimac', 'lóginac', 'lógioac', 'lógipac', 'lógiqac', 'lógirac', 'lógisac', 'lógitac', 'lógiuac', 'lógivac', 'lógiwac', 'lógixac', 'lógiyac', 'lógizac', 'lógiáac', 'lógiâac', 'lógiàac', 'lógiãac', 'lógiéac', 'lógiêac', 'lógièac', 'lógiẽac', 'lógiíac', 'lógiîac', 'lógiìac', 'lógiĩac', 'lógióac', 'lógiôac', 'lógiõac', 'lógiòac', 'lógiúac', 'lógiûac', 'lógiùac', 'lógiũac', 'lógiçac', 'lógiaac', 'lógiabc', 'lógiacc', 'lógiadc', 'lógiaec', 'lógiafc', 'lógiagc', 'lógiahc', 'lógiaic', 'lógiajc', 'lógiakc', 'lógialc', 'lógiamc', 'lógianc', 'lógiaoc', 'lógiapc', 'lógiaqc', 'lógiarc', 'lógiasc', 'lógiatc', 'lógiauc', 'lógiavc', 'lógiawc', 'lógiaxc', 'lógiayc', 'lógiazc', 'lógiaác', 'lógiaâc', 'lógiaàc', 'lógiaãc', 'lógiaéc', 'lógiaêc', 'lógiaèc', 'lógiaẽc', 'lógiaíc', 'lógiaîc', 'lógiaìc', 'lógiaĩc', 'lógiaóc', 'lógiaôc', 'lógiaõc', 'lógiaòc', 'lógiaúc', 'lógiaûc', 'lógiaùc', 'lógiaũc', 'lógiaçc', 'lógiaca', 'lógiacb', 'lógiacc', 'lógiacd', 'lógiace', 'lógiacf', 'lógiacg', 'lógiach', 'lógiaci', 'lógiacj', 'lógiack', 'lógiacl', 'lógiacm', 'lógiacn', 'lógiaco', 'lógiacp', 'lógiacq', 'lógiacr', 'lógiacs', 'lógiact', 'lógiacu', 'lógiacv', 'lógiacw', 'lógiacx', 'lógiacy', 'lógiacz', 'lógiacá', 'lógiacâ', 'lógiacà', 'lógiacã', 'lógiacé', 'lógiacê', 'lógiacè', 'lógiacẽ', 'lógiací', 'lógiacî', 'lógiacì', 'lógiacĩ', 'lógiacó', 'lógiacô', 'lógiacõ', 'lógiacò', 'lógiacú', 'lógiacû', 'lógiacù', 'lógiacũ', 'lógiacç', 'ógiac', 'lgiac', 'lóiac', 'lógac', 'lógic', 'lógia', 'lógiac', 'aógiac', 'bógiac', 'cógiac', 'dógiac', 'eógiac', 'fógiac', 'gógiac', 'hógiac', 'iógiac', 'jógiac', 'kógiac', 'lógiac', 'mógiac', 'nógiac', 'oógiac', 'pógiac', 'qógiac', 'rógiac', 'sógiac', 'tógiac', 'uógiac', 'vógiac', 'wógiac', 'xógiac', 'yógiac', 'zógiac', 'áógiac', 'âógiac', 'àógiac', 'ãógiac', 'éógiac', 'êógiac', 'èógiac', 'ẽógiac', 'íógiac', 'îógiac', 'ìógiac', 'ĩógiac', 'óógiac', 'ôógiac', 'õógiac', 'òógiac', 'úógiac', 'ûógiac', 'ùógiac', 'ũógiac', 'çógiac', 'lagiac', 'lbgiac', 'lcgiac', 'ldgiac', 'legiac', 'lfgiac', 'lggiac', 'lhgiac', 'ligiac', 'ljgiac', 'lkgiac', 'llgiac', 'lmgiac', 'lngiac', 'logiac', 'lpgiac', 'lqgiac', 'lrgiac', 'lsgiac', 'ltgiac', 'lugiac', 'lvgiac', 'lwgiac', 'lxgiac', 'lygiac', 'lzgiac', 'lágiac', 'lâgiac', 'làgiac', 'lãgiac', 'légiac', 'lêgiac', 'lègiac', 'lẽgiac', 'lígiac', 'lîgiac', 'lìgiac', 'lĩgiac', 'lógiac', 'lôgiac', 'lõgiac', 'lògiac', 'lúgiac', 'lûgiac', 'lùgiac', 'lũgiac', 'lçgiac', 'lóaiac', 'lóbiac', 'lóciac', 'lódiac', 'lóeiac', 'lófiac', 'lógiac', 'lóhiac', 'lóiiac', 'lójiac', 'lókiac', 'lóliac', 'lómiac', 'lóniac', 'lóoiac', 'lópiac', 'lóqiac', 'lóriac', 'lósiac', 'lótiac', 'lóuiac', 'lóviac', 'lówiac', 'lóxiac', 'lóyiac', 'lóziac', 'lóáiac', 'lóâiac', 'lóàiac', 'lóãiac', 'lóéiac', 'lóêiac', 'lóèiac', 'lóẽiac', 'lóíiac', 'lóîiac', 'lóìiac', 'lóĩiac', 'lóóiac', 'lóôiac', 'lóõiac', 'lóòiac', 'lóúiac', 'lóûiac', 'lóùiac', 'lóũiac', 'lóçiac', 'lógaac', 'lógbac', 'lógcac', 'lógdac', 'lógeac', 'lógfac', 'lóggac', 'lóghac', 'lógiac', 'lógjac', 'lógkac', 'lóglac', 'lógmac', 'lógnac', 'lógoac', 'lógpac', 'lógqac', 'lógrac', 'lógsac', 'lógtac', 'lóguac', 'lógvac', 'lógwac', 'lógxac', 'lógyac', 'lógzac', 'lógáac', 'lógâac', 'lógàac', 'lógãac', 'lógéac', 'lógêac', 'lógèac', 'lógẽac', 'lógíac', 'lógîac', 'lógìac', 'lógĩac', 'lógóac', 'lógôac', 'lógõac', 'lógòac', 'lógúac', 'lógûac', 'lógùac', 'lógũac', 'lógçac', 'lógiac', 'lógibc', 'lógicc', 'lógidc', 'lógiec', 'lógifc', 'lógigc', 'lógihc', 'lógiic', 'lógijc', 'lógikc', 'lógilc', 'lógimc', 'lóginc', 'lógioc', 'lógipc', 'lógiqc', 'lógirc', 'lógisc', 'lógitc', 'lógiuc', 'lógivc', 'lógiwc', 'lógixc', 'lógiyc', 'lógizc', 'lógiác', 'lógiâc', 'lógiàc', 'lógiãc', 'lógiéc', 'lógiêc', 'lógièc', 'lógiẽc', 'lógiíc', 'lógiîc', 'lógiìc', 'lógiĩc', 'lógióc', 'lógiôc', 'lógiõc', 'lógiòc', 'lógiúc', 'lógiûc', 'lógiùc', 'lógiũc', 'lógiçc', 'lógiaa', 'lógiab', 'lógiac', 'lógiad', 'lógiae', 'lógiaf', 'lógiag', 'lógiah', 'lógiai', 'lógiaj', 'lógiak', 'lógial', 'lógiam', 'lógian', 'lógiao', 'lógiap', 'lógiaq', 'lógiar', 'lógias', 'lógiat', 'lógiau', 'lógiav', 'lógiaw', 'lógiax', 'lógiay', 'lógiaz', 'lógiaá', 'lógiaâ', 'lógiaà', 'lógiaã', 'lógiaé', 'lógiaê', 'lógiaè', 'lógiaẽ', 'lógiaí', 'lógiaî', 'lógiaì', 'lógiaĩ', 'lógiaó', 'lógiaô', 'lógiaõ', 'lógiaò', 'lógiaú', 'lógiaû', 'lógiaù', 'lógiaũ', 'lógiaç', 'lógiaca', 'lógiacb', 'lógiacc', 'lógiacd', 'lógiace', 'lógiacf', 'lógiacg', 'lógiach', 'lógiaci', 'lógiacj', 'lógiack', 'lógiacl', 'lógiacm', 'lógiacn', 'lógiaco', 'lógiacp', 'lógiacq', 'lógiacr', 'lógiacs', 'lógiact', 'lógiacu', 'lógiacv', 'lógiacw', 'lógiacx', 'lógiacy', 'lógiacz', 'lógiacá', 'lógiacâ', 'lógiacà', 'lógiacã', 'lógiacé', 'lógiacê', 'lógiacè', 'lógiacẽ', 'lógiací', 'lógiacî', 'lógiacì', 'lógiacĩ', 'lógiacó', 'lógiacô', 'lógiacõ', 'lógiacò', 'lógiacú', 'lógiacû', 'lógiacù', 'lógiacũ', 'lógiacç', 'ólgiac', 'lgóiac', 'lóigac', 'lógaic', 'lógica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator(test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVoBpGnoxKf6",
        "outputId": "98c47ecc-5d22-494b-bf2f-fe0a9d22d571"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.34% of 186 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I obtained better results compared to the previous evaluation which had a slightly higher percentage than 40% of the 186 words."
      ],
      "metadata": {
        "id": "uYjPLYllDl3d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the Corrector"
      ],
      "metadata": {
        "id": "r3TShMx5D74A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluator with unknown word rate\n",
        "def evaluator(tests, vocabulary):\n",
        "    word_count = len(tests)\n",
        "    correct_count = 0\n",
        "    unknown = 0\n",
        "    for correct, wrong in tests:\n",
        "        corrected_word = corrector(wrong)\n",
        "        if corrected_word == correct:\n",
        "            correct_count += 1\n",
        "        else:\n",
        "            unknown += (correct not in vocabulary)                              # Counting when the correct word is unknown in my vocabulary\n",
        "    accuracy_rate = round(correct_count * 100 / word_count, 2)\n",
        "    unknown_rate = round(unknown * 100 / word_count, 2)                         # Percentage of unknown words\n",
        "\n",
        "    print(f\"{accuracy_rate}% of {word_count} words, unknown is {unknown_rate}%\")\n",
        "\n",
        "vocabulary = set(normalized_list)                                               # Non-repetitive words\n",
        "evaluator(test_list, vocabulary)"
      ],
      "metadata": {
        "id": "8tYWlLPOEGps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199b860e-279f-48a4-990d-babaf4ea94f6"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.34% of 186 words, unknown is 6.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, the corrector only corrects words that are at a single distance from a correct word. To improve this, I need to enhance my word generator."
      ],
      "metadata": {
        "id": "LX2H5taAWOZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"lóiigica\"\n",
        "\n",
        "def improved_generator(generated_words):\n",
        "    new_words = []\n",
        "    for word in generated_words:\n",
        "        new_words += word_generator(word)                                       # New words at two distances from corrected words\n",
        "    return new_words\n",
        "\n",
        "words_g = improved_generator(word_generator(word))\n",
        "\"lógica\" in words_g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRsiIAzrVGYD",
        "outputId": "0ea134e8-12ed-493f-d6b3-a26c3fc6558a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(words_g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYrMenVQWlX9",
        "outputId": "ea33e8fd-f9a0-4115-a3d0-dc2eff980079"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "787396"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def new_corrector(word):\n",
        "    generated_words = word_generator(word)\n",
        "    improved_words = improved_generator(generated_words)                        # Includes the generation of improved words\n",
        "    all_words = set(generated_words + improved_words)                           # Includes the improved words without repetition\n",
        "    candidates = [word]\n",
        "    for word in all_words:\n",
        "        if word in vocabulary:\n",
        "            candidates.append(word)\n",
        "    correct_word = max(candidates, key=probability)                             # If the word is contained in the vocabulary, it will return the word with the highest probability of being the correct word\n",
        "    return correct_word\n",
        "\n",
        "new_corrector(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "SA5C36Ntb9R7",
        "outputId": "1dcb66a2-f12a-456c-eeb3-480ae29089ff"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lógica'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluator(tests, vocabulary):\n",
        "    word_count = len(tests)\n",
        "    correct_count = 0\n",
        "    unknown = 0\n",
        "\n",
        "    # Returns the corrected word plus the count of unknown words\n",
        "    for correct, wrong in tests:\n",
        "        corrected_word = new_corrector(wrong)\n",
        "        unknown += (correct not in vocabulary)\n",
        "        # The condition returns the count of correct words for each correct answer\n",
        "        if corrected_word == correct:\n",
        "            correct_count += 1\n",
        "        else:\n",
        "            print(wrong + \"-\" + corrector(wrong) + \"-\" + corrected_word)\n",
        "\n",
        "    accuracy_rate = round(correct_count * 100 / word_count, 2)\n",
        "    unknown_rate = round(unknown * 100 / word_count, 2)\n",
        "\n",
        "    print(f\"{accuracy_rate}% of {word_count} words, unknown is {unknown_rate}%\")\n",
        "\n",
        "vocabulary = set(normalized_list)\n",
        "evaluator(test_list, vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKtfK4JNd7yt",
        "outputId": "23630163-ec01-4e7d-f97d-0e2450a4d727"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "esje-esse-se\n",
            "sãêo-são-não\n",
            "dosa-dos-do\n",
            "eme-em-de\n",
            "eàssa-essa-esse\n",
            "daõs-das-da\n",
            "céda-cada-da\n",
            "noâ-no-o\n",
            "enêão-então-não\n",
            "tĩem-tem-em\n",
            "nossah-nossa-nosso\n",
            "teb-tem-de\n",
            "atĩ-até-a\n",
            "âem-em-de\n",
            "foo-foi-o\n",
            "serr-ser-se\n",
            "entke-entre-então\n",
            "van-vai-a\n",
            "çeus-seus-seu\n",
            "eû-e-de\n",
            "temeo-tempo-temos\n",
            "semre-sempre-ser\n",
            "elaá-ela-ele\n",
            "síó-só-se\n",
            "siàe-site-se\n",
            "seém-sem-em\n",
            "peln-pelo-ele\n",
            "aléra-alura-agora\n",
            "tdia-dia-da\n",
            "tuúo-tudo-tipo\n",
            "jé-é-de\n",
            "sãô-são-não\n",
            "odos-dos-do\n",
            "siua-sua-seu\n",
            "elpe-ele-esse\n",
            "teos-temos-os\n",
            "eũsa-essa-esse\n",
            "vjmos-vamos-temos\n",
            "dms-dos-de\n",
            "cava-java-para\n",
            "ános-nos-no\n",
            "èaso-caso-as\n",
            "túem-tem-em\n",
            "daáos-dados-dos\n",
            "nossk-nosso-nosso\n",
            "tãer-ter-ser\n",
            "vté-até-é\n",
            "búm-bem-um\n",
            "sçerá-será-ser\n",
            "entró-entre-então\n",
            "uai-vai-a\n",
            "sâus-seus-seu\n",
            "ìeu-seu-de\n",
            "fual-qual-sua\n",
            "elal-ela-ele\n",
            "skó-só-se\n",
            "secm-sem-em\n",
            "aluéa-alura-além\n",
            "dil-dia-de\n",
            "sód-só-se\n",
            "eúaa-aeúaa-essa\n",
            "ró-só-de\n",
            "dĩaz-adĩaz-da\n",
            "correptor-corretor-correto\n",
            "trtica-tática-prática\n",
            "ewpoderamento-aewpoderamento-ewpoderamento\n",
            "îgato-gato-fato\n",
            "cakvalo-acakvalo-carvalho\n",
            "canelac-acanelac-janela\n",
            "tênisy-atênisy-tênisy\n",
            "anciosa-aanciosa-ansioso\n",
            "ancciosa-aancciosa-ancciosa\n",
            "ansioa-aansioa-ensina\n",
            "asterístico-aasterístico-asterístico\n",
            "entertido-aentertido-entendido\n",
            "ritimo-ritmo-ótimo\n",
            "indiota-aindiota-indica\n",
            "tomare-tomar-tomar\n",
            "seje-seja-se\n",
            "provalecer-aprovalecer-prevaleceu\n",
            "esteje-esteja-este\n",
            "mindigo-amindigo-indico\n",
            "pertubar-apertubar-derrubar\n",
            "55.38% of 186 words, unknown is 6.99%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Considering the line \"odos-dos-do\" the word \"dos\" is already correct, however, the code corrects it to \"do\". Therefore, one of the errors of the improved corrector is associated with the fact that it generates both the possible correct word and an existing variation in the vocabulary, which has a higher frequency. Hence, I will use the consolidated evaluator with the old corrector."
      ],
      "metadata": {
        "id": "_L2Re3mRj6mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"lóiigica\"\n",
        "print(new_corrector(word))\n",
        "print(corrector(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OZTminqkXZG",
        "outputId": "058ca15e-6693-4c44-8ba3-14d0890e2c87"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lógica\n",
            "alóiigica\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluator(tests, vocabulary):\n",
        "    word_count = len(tests)\n",
        "    correct_count = 0\n",
        "    unknown = 0\n",
        "    for correct, wrong in tests:\n",
        "        corrected_word = corrector(wrong)\n",
        "        unknown += (correct not in vocabulary)\n",
        "        if corrected_word == correct:\n",
        "            correct_count += 1\n",
        "    accuracy_rate = round(correct_count * 100 / word_count, 2)\n",
        "    unknown_rate = round(unknown * 100 / word_count, 2)\n",
        "    print(f\"{accuracy_rate}% of {word_count} words, unknown is {unknown_rate}%\")\n",
        "\n",
        "vocabulary = set(normalized_list)\n",
        "evaluator(test_list, vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv3R92lcjG7v",
        "outputId": "c4a8db5f-0a6d-4ce7-f41d-ec2cd190d8ac"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.34% of 186 words, unknown is 6.99%\n"
          ]
        }
      ]
    }
  ]
}